services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --locale=en_US.UTF-8"
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: >
      redis-server 
      --appendonly yes 
      --maxmemory ${REDIS_MAX_MEMORY:-512mb} 
      --maxmemory-policy allkeys-lru
      ${REDIS_PASSWORD:+--requirepass $REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "${REDIS_PASSWORD:+-a $REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # MinIO Object Storage
  minio:
    image: minio/minio:latest
    container_name: minio
    restart: unless-stopped
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "${PROTOCOL}://${DOMAIN}:${MINIO_PORT}/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # etcd for Milvus
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: etcd
    restart: unless-stopped
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - rag_network

  # Milvus Public Instance
  milvus_public:
    image: milvusdb/milvus:v2.6.0
    container_name: milvus_public
    restart: unless-stopped
    ports:
      - "9091:9091"
    environment:
      ETCD_ENDPOINTS: etcd:2379
      ETCD_ROOT_PATH: by-public
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    volumes:
      - milvus_public_data:/var/lib/milvus
    depends_on:
      etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9091/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: milvus run standalone

  # Milvus Private Instance
  milvus_private:
    image: milvusdb/milvus:v2.6.0
    container_name: milvus_private
    restart: unless-stopped
    ports:
      - "${MILVUS_PRIVATE_PORT:-19531}:19530"
    environment:
      ETCD_ENDPOINTS: etcd:2379
      ETCD_ROOT_PATH: by-private
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    volumes:
      - milvus_private_data:/var/lib/milvus
    depends_on:
      etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9091/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: milvus run standalone

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - rag_network

  # Kafka Message Queue
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    restart: unless-stopped
    ports:
      - "${KAFKA_PORT:-9092}:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - rag_network

  # Ollama Local LLM (Optional)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: unless-stopped
  #   ports:
  #     - "${OLLAMA_PORT:-11434}:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #   networks:
  #     - rag_network
  #   profiles:
  #     - ollama
  #     - with-local-llm
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  # Main API Application
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
      target: ${ENV:-development}
    container_name: api
    restart: unless-stopped
    ports:
      - "${HOST_APP_PORT:-15000}:8000"
    environment:
      # Application Settings
      - APP_NAME=${APP_NAME}
      - APP_VERSION=${APP_VERSION}
      - APP_HOST=0.0.0.0
      - APP_PORT=8000
      - ENV=${ENV}
      - TIMEZONE=${TIMEZONE}
      
      # Security
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_ALGORITHM=${JWT_ALGORITHM}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES}
      - REFRESH_TOKEN_EXPIRE_DAYS=${REFRESH_TOKEN_EXPIRE_DAYS}
      
      # Database
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      
      # Redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      
      # Dual Milvus
      - MILVUS_PUBLIC_URI=http://${MILVUS_PUBLIC_HOST}:19530
      - MILVUS_PRIVATE_URI=http://${MILVUS_PRIVATE_HOST}:19530
      - MILVUS_COLLECTION_PREFIX=${MILVUS_COLLECTION_PREFIX}
      - MILVUS_VECTOR_DIM=${MILVUS_VECTOR_DIM}
      
      # MinIO Storage
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_SECURE=false
      - STORAGE_BUCKET_PREFIX=${STORAGE_BUCKET_PREFIX}
      
      # Kafka
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_DOCUMENT_TOPIC=${KAFKA_DOCUMENT_TOPIC}
      - KAFKA_CONSUMER_GROUP=${KAFKA_CONSUMER_GROUP}
      
      # BGE-M3 Embedding
      - EMBEDDING_MODEL=${BGE_M3_MODEL}
      - EMBEDDING_DIMENSIONS=${MILVUS_VECTOR_DIM}
      - EMBEDDING_BATCH_SIZE=${BGE_M3_BATCH_SIZE}
      - BGE_M3_USE_FP16=${BGE_M3_USE_FP16}
      - BGE_M3_MAX_LENGTH=${BGE_M3_MAX_LENGTH}
      
      # MMR Configuration
      - MMR_LAMBDA_DEFAULT=${MMR_LAMBDA_DEFAULT}
      - MMR_TOP_K_DEFAULT=${MMR_TOP_K_DEFAULT}
      
      # Document Processing
      - DOCLING_ENABLE_OCR=${DOCLING_ENABLE_OCR}
      - DOCLING_ENABLE_TABLE_STRUCTURE=${DOCLING_ENABLE_TABLE_STRUCTURE}
      - DOCLING_ENABLE_PICTURE=${DOCLING_ENABLE_PICTURE}
      - LANGCHAIN_FALLBACK_ENABLED=${LANGCHAIN_FALLBACK_ENABLED}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB}
      
      # Workflow
      - WORKFLOW_MAX_ITERATIONS=${WORKFLOW_MAX_ITERATIONS}
      - WORKFLOW_TIMEOUT_SECONDS=${WORKFLOW_TIMEOUT_SECONDS}
      - WORKFLOW_ENABLE_REFLECTION=${WORKFLOW_ENABLE_REFLECTION}
      - WORKFLOW_ENABLE_SEMANTIC_ROUTING=${WORKFLOW_ENABLE_SEMANTIC_ROUTING}
      
      # Orchestrator
      - ORCHESTRATOR_ENABLED=${ORCHESTRATOR_ENABLED}
      - ORCHESTRATOR_STRATEGY=${ORCHESTRATOR_STRATEGY}
      - ORCHESTRATOR_MAX_AGENTS_PER_QUERY=${ORCHESTRATOR_MAX_AGENTS_PER_QUERY}
      - ORCHESTRATOR_CONFIDENCE_THRESHOLD=${ORCHESTRATOR_CONFIDENCE_THRESHOLD}
      
      # Ollama (if enabled)
      - OLLAMA_BASE_URL=http://ollama:11434
      
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_DIR=/app/logs
      
      # CORS
      - CORS_ORIGINS=${BASE_URL},${API_URL},http://localhost:3001,https://aichatbot.hoangdieuit.io.vn

      # MAINTAINER
      - MAINTAINER_USERNAME=${MAINTAINER_USERNAME}
      - MAINTAINER_EMAIL=${MAINTAINER_EMAIL}
      - MAINTAINER_PASSWORD=${MAINTAINER_PASSWORD}

      # Email SMTP
      - EMAIL_TEMPLATES_DIR=${EMAIL_TEMPLATES_DIR}
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_TLS=${SMTP_TLS}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
      - EMAIL_FROM_NAME=${EMAIL_FROM_NAME}
      - EMAIL_FROM=${EMAIL_FROM}
      
    volumes:
      - ./api:/app
      - ./logs:/app/logs
      - ./uploads:/app/uploads
      - document_storage:/app/documents
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      milvus_public:
        condition: service_healthy
      milvus_private:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS \"$PROTOCOL://$DOMAIN:${APP_PORT:-8000}/api/v1/health/live\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.external-url=${PROMETHEUS_URL}'
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=${GRAFANA_URL}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - rag_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana-loader:
    image: alpine:3.19
    container_name: grafana-loader
    restart: "no"
    depends_on:
      grafana:
        condition: service_started
    environment:
      - GRAFANA_API_URL=${GRAFANA_INTERNAL_URL:-http://grafana:3000}
      - GRAFANA_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GRAFANA_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - DASHBOARD_IDS=${GRAFANA_DASHBOARD_IDS:-2204}
      - PROM_DS_UID=${PROM_DS_UID:-prometheus}
      - LOKI_DS_UID=${LOKI_DS_UID:-loki}
    command: >
      sh -lc "apk add --no-cache curl jq >/dev/null &&
      echo 'Waiting Grafana...' &&
      until curl -sf $$GRAFANA_API_URL/api/health >/dev/null; do sleep 3; done &&
      for id in $$(echo $$DASHBOARD_IDS | tr ',' ' '); do
        echo Importing dashboard $$id;
        json=$$(curl -sf https://grafana.com/api/dashboards/$$id/revisions/latest/download);
        payload=$$(jq -n --argjson db \"$$json\" --arg prom \"$$PROM_DS_UID\" --arg loki \"$$LOKI_DS_UID\" '{dashboard: $$db, overwrite: true, inputs: [ {name:\"DS_PROMETHEUS\", type:\"datasource\", pluginId:\"prometheus\", value:$$prom}, {name:\"DS_LOKI\", type:\"datasource\", pluginId:\"loki\", value:$$loki} ] }');
        curl -sf -u \"$$GRAFANA_ADMIN_USER:$$GRAFANA_ADMIN_PASSWORD\" -H 'Content-Type: application/json' -X POST \"$$GRAFANA_API_URL/api/dashboards/import\" -d \"$$payload\" || true;
      done && echo 'Done'"
    networks:
      - rag_network

  loki:
    image: grafana/loki:2.9.4
    container_name: loki
    restart: unless-stopped
    ports:
      - "${LOKI_PORT:-3100}:3100"
    command: -config.file=/etc/loki/config.yml
    volumes:
      - ./monitoring/loki/config.yml:/etc/loki/config.yml:ro
      - loki_data:/loki
    networks:
      - rag_network

  promtail:
    image: grafana/promtail:2.9.4
    container_name: promtail
    restart: unless-stopped
    command:
      - -config.file=/etc/promtail/config.yml
      - -config.expand-env=true
    volumes:
      - ./monitoring/promtail/config.yml:/etc/promtail/config.yml:ro
      - ./logs:/app/logs:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    environment:
      - LOKI_URL=${LOKI_URL}
    depends_on:
      - loki
    networks:
      - rag_network

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: cadvisor
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - rag_network

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    restart: unless-stopped
    environment:
      - REDIS_ADDR=redis://redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    depends_on:
      - redis
    networks:
      - rag_network

  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    restart: unless-stopped
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag_network

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: kafka-exporter
    restart: unless-stopped
    command:
      - --kafka.server=kafka:9092
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - rag_network

# Named Volumes
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  minio_data:
    driver: local
  etcd_data:
    driver: local
  milvus_public_data:
    driver: local
  milvus_private_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  # ollama_data:
  #   driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  document_storage:
    driver: local
  loki_data:
    driver: local

# Networks
networks:
  rag_network:
    driver: bridge
    labels:
      - "project=multi-agent-rag"
      - "environment=${ENV:-development}"